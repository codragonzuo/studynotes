
## MongoDB性能篇之创建索引，组合索引，唯一索引，删除索引和explain执行计划

https://www.jb51.net/article/80067.htm


## 实现MongoDB读写分离的“读偏好”介绍

https://www.cnblogs.com/xuliuzai/p/9624508.html

大部分MongoDB驱动支持读偏好设置（read preference；或翻译为读取首选项），用来告诉驱动从特定的节点读取数据。

primary — 这是默认的设置，表明只从可复制集的主节点读取数据，因此具有强一致性。如果可复制集有问题，并且没有可选举的从节点，就表示出现错误。

premaryPreferred — 设置了此参数的驱动会从主节点读取数据，除非某些原因使主节点不可用或者没有主节点，此时它会从从节点读取数据。此种设置下，读请求无法保证一致性。

secondary — 这个设置告诉驱动应该一直从从节点读取数据。这种设置对于我们想确保读请求不会影响主节点的写入请求时非常有用。如果没有可用的从节点，读请求会抛出异常。

secondarypreferred—读请求会发出到从节点，除非没有从节点可用，此时才会从主节点读取。

nearest –驱动会尝试从最近的可复制集成员节点读取读取数据，通过网络延迟判断。可以是主节点也可以是从节点。因此读请求只会发送给驱动认为最快通信的节点。

primary是唯一一个可以确保读一致的模式。因为写请求首先在主节点完成，从服务器的更新会有些延迟，所以可能在从节点无法找到刚刚在主节点写入的文档数据。

汇总以上知识，各偏好设置下读取数据请求所发往的节点如下所示：

![](https://images2018.cnblogs.com/blog/780228/201809/780228-20180910235204059-389264792.png)

2  最大过期时间

MongoDB 3.4及更新的版本新增了maxStalenessSeconds设置。

副本集的从节点可能因为网络阻塞、磁盘吞吐低、长时间执行操作等，导致其落后于主节点。读设置maxStalenessSeconds选项让你对从节点读取定义了最大落后或“过期”时间。当从节点估计过期时间超过了maxStalenessSeconds,客户端会停止使用它进行读操作。

最大过期和primary模式不匹配，只有选择从节点成员读取操作才能应用。

当选择了使用maxStalenessSeconds进行读操作的服务端，客户端会通过比较从节点和主节点的最后一次写时间来估计从节点的过期程度。客户端会把连接指向估计落后小于等于maxStalenessSeconds的从节点。如果没有主节点，客户端使用从节点间的最近一次写操作来比较。

默认是没有最大过期时间并且客户端也不会在指向读操作时考虑从节点的落后。

必须定义maxStalenessSeconds的值大于等于90秒：定义一个更小的值会抛出异常。客户端通过定期检查每个副本集成员最后一次写时间来估计副本集过期程度。因为检查不频繁，所以估计是粗略的。因此，客户端不能强制maxStalenessSecconds小于90秒。

## Mongos 数据自动分片
对于一个读写操作，mongos需要知道应该将其路由到哪个复制集上，mongos通过将片键空间划分为若干个区间，计算出一个操作的片键的所属区间对应的复制集来实现路由。

Collection1 被划分为4个chunk，其中  
chunk1 包含（-INF，1) , chunk3 包含[20, 99) 的数据，放在shard1上。  
chunk2 包含 [1,20), chunk4 包含[99, INF) 的数据，放在shard2上。  
chunk 的信息存放在configServer 的mongod实例的 config.chunks 表中，格式如下：  

```
{   
    "_id" : "mydb.foo-a_\"cat\"",   
    "lastmod" : Timestamp(1000, 3),  
    "lastmodEpoch" : ObjectId("5078407bd58b175c5c225fdc"),   
    "ns" : "mydb.foo",   
    "min" : {         "animal" : "cat"   },   
    "max" : {         "animal" : "dog"   },   
    "shard" : "shard0004"
}
```
![](https://mc.qcloudimg.com/static/img/98ca4095b687757cb69096724d70e72a/image.png)
值得注意的是：chunk是一个逻辑上的组织结构，并不涉及到底层的文件组织方式。


## 为什么不用secondaryPreferred模式？

     从模式的字面意思看，secondaryPreferred模式比secondary模式更能保证服务的可用性，但是为什么不选选择secondaryPreferred？原因是在某些场景下，所有的备份节点都宕机后，所有的读请求也将转移到主节点，假如主节点不能同时处理这些读请求，那么读请求将会和写请求竞争资源，导致主节点负载加大，影响读写性能，严重情况会造成主节点宕机。

对于读密集型应用，线上使用复制集集群方式，能保证服务的可用性，由于数据的及时性要求不是特别高（前台页面展示内容），能够接受短时间内的数据延迟，因此选择secondary模式是非常合适的。

MongoDB的副本集本质上就是一组mongod进程。复制集的成员有:  
　　　　1.Primary:主节点，负责所有的写操作；  
　　　　2.Secondaries:从节点，同步主节点的数据，保存数据副本；  
　　　　3.Arbiter:仲裁节点，不保存数据，只有一个投票的作用；  
　　副本集运行过程：主节点是集群中唯一一个负责写操作的节点，主节点的写操作都会记录在其操作日志(oplog，是一个 capped collection)中，从节点复制主节点的oplog日志并执行日志中的命令，以此保持数据和主节点一致。副本集的所有节点都可以进行读操作，但是应用程序默认从主节点读取数据。当主节点一段时间(当前默认为10s)不和从节点通信,集群就会开始投票选取新的主节点。下图来自官网，描述了一个一主两从的副本集的结构，应用程序的读写操作默认都是通过主节点进行的。  


![](https://img2018.cnblogs.com/blog/1007918/201907/1007918-20190708165842417-1506987260.png)


设置节点的优先级

在部署的时候，我们一般更愿意让稳定且性能好的设备在选举时优先作为主节点，让性能差的服务器不能被选举为主节点。这就要用到优先级了，各个节点的默认优先级都是1，我们可以更改各个节点的优先级，优先级越高，被选举为主节点的几率就越大，优先级为0的节点不能被选举为主节点。使用mongo shell执行下边的命令就可以更改各个节点的优先级。

#Sharing分片简介
　　除了副本集，在Mongodb里面存在另一种集群：分片集群。所谓分片简单来说就是将一个完整的数据分割后存储在不同的节点上。当MongoDB存储海量的数据时，一台机器不足以存储数据，或者数据过多造成读写吞吐量不能满足我们的需求时，可以考虑使用分片集群。

　　举一个栗子：例如我们有1个亿的用户信息，选择用户的name列作为分片键(shard key),将用户信息存储到两个Shard Server中，mongoDB会自动根据分片键将用户数据进行分片，假如分片后第一个片(shard1)存储了名字首字母为a~m的用户信息，第二个片(shard2)存储了名字首字母为n~z的用户信息。当我们要查询name=jack的用户时，因为jack的首字母j在a和m之间，所以分片集群会直接到shard1中查找，这样查询效率就会提高很多；如果我们要插入一个name=tom的用户，因为t在n~z之间，所以tom的信息会插入shard2中。这个栗子的分片键是name，当我们要查询生日为某一天的用户时(出生日期不是分片键)，mongoDB还是会去查询所有分片服务器的数据。

　　分片集群的基本结构如下：
 
 ![](https://img2018.cnblogs.com/blog/1007918/201907/1007918-20190713171437656-1079860844.png)
 
 分片集群主要包含三个组件(都是mongod进程)：

1 Shard Server

　   存储角色，真实的业务数据都保存在该角色中。在生产环境中每一个shard server都应该使用副本集，用于防止数据丢失，实现高可用。

2 Config Server

　　配置角色，存储sharing集群的元数据和配置信息。分片集群判断我们查询的数据在哪个shard中，或者要将数据插入到哪一个shard中就是由Config Server中的配置决定的。Config Server也要使用副本集充当，不然Config Server宕机，配置信息就无从获取了。

3 mongos

　　路由角色，这是应用程序访问分片集群的入口，我们通过连接mongos来访问分片集群，mongos让整个集群看起来就像一个单独的数据库。mongos同样推荐配置成副本集，不然路由角色宕机，应用程序就无法访问集群。

　　分片集群各个角色一般都要配置为副本集，所以需要较多的mongod进程，如sharing 集群中的三个角色都使用一主两从的副本集就需要9个mongod进程.
  

